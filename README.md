# Visiont Transformers implementation with PyTorch for MNIST Dataset

## Introduction
This is a simple implementation of Vision Transformers for MNIST dataset. The code is based on the paper [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) using PyTorch.

It's been tested using the [MNIST dataset](https://www.kaggle.com/competitions/digit-recognizer)

* It has an accuracy of 93.8% on the test set.

(reference: [yt](https://www.youtube.com/watch?v=Vonyoz6Yt9c), [kaggle](https://www.kaggle.com/competitions/digit-recognizer))